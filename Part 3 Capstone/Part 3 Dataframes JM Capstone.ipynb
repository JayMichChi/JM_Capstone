{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.style.use('seaborn-white')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('../Part 2 Capstone/df2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['MONTH_NAME'] = df1['MONTH_NAME'].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " event_types = ['Drought' ,'Flood' ,'Winter Storm', 'OTHER', 'High Wind' ,'ThunderStorm',\n",
    " 'Wildfire', 'Rip Current' ,'Tropical Storm' ,'Tornado' ,'Hurricane', 'Tsunami',\n",
    " 'Landslide']\n",
    " for i in event_types:\n",
    "     df1['is_'+i] = df1['EVENT_TYPE'].apply(lambda x: 1 if i in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_hurricane_model = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_hurricane_model.drop([ 'EVENT_ID', u'CZ_NAME', u'CATEGORY', u'TOR_F_SCALE', u'TOR_LENGTH',\n",
    "       u'TOR_WIDTH',u'MONTH_NAME', u'is_Drought', u'is_Flood', u'is_Winter Storm', u'is_OTHER', u'is_High Wind', u'is_ThunderStorm', u'is_Wildfire',\n",
    "       u'is_Rip Current', u'is_Tropical Storm', u'is_Tornado',u'is_Tsunami', u'is_Landslide'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_hurricane_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_cols = [u'is_Hurricane', u'EVENT_TYPE', u'EPISODE_ID', u'DATE', u'STATE', u'INJURIES_DIRECT',\n",
    "       u'INJURIES_INDIRECT', u'TOTAL_INJURIES', u'DEATHS_DIRECT',\n",
    "       u'DEATHS_INDIRECT', u'TOTAL_DEATHS', u'CASUALTIES', u'DAMAGE_PROPERTY',\n",
    "       u'DAMAGE_CROPS', u'COMBINED_DAMAGE', u'EPISODE_NARRATIVE',\n",
    "       u'EVENT_NARRATIVE', u'YEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_hurricane_model = is_hurricane_model[h_cols] \n",
    "is_hurricane_model['STATE'] = is_hurricane_model['STATE'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "\n",
    "y = LabelEncoder().fit_transform(df1['is_Hurricane'])\n",
    "x = df1['TOTAL_DEATHS'].reshape(-1,1)\n",
    "model_1 = logmodel.fit(x,y)\n",
    "\n",
    "model_1.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(penalty='l2', C=1)\n",
    "y1 = is_hurricane_model['is_Hurricane']\n",
    "x1 = is_hurricane_model[[ u'EPISODE_ID',  u'INJURIES_DIRECT',\n",
    "       u'INJURIES_INDIRECT', u'TOTAL_INJURIES', u'DEATHS_DIRECT',\n",
    "       u'DEATHS_INDIRECT', u'TOTAL_DEATHS', u'CASUALTIES', u'DAMAGE_PROPERTY',\n",
    "       u'DAMAGE_CROPS', u'COMBINED_DAMAGE', u'YEAR']]\n",
    "             \n",
    "model1 = logreg.fit(x1,y1)\n",
    "model1.score(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_class1 = model1.predict(x1)\n",
    "confusion_matrix(y1, predicted_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(y1, predicted_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,8))\n",
    "sbn.heatmap(is_hurricane_model.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logisticTTS = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelTTS = logisticTTS.fit(x_train, y_train)\n",
    "\n",
    "modelTTS.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_train = modelTTS.predict(x_train)\n",
    "confusion_matrix(y_train, predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelTTS.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_test = modelTTS.predict(x_test)\n",
    "confusion_matrix(y_test, predict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_score = logisticTTS.decision_function(x_test)\n",
    "\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict()\n",
    "\n",
    "print roc_curve(y_test, Y_score)\n",
    "\n",
    "FPR[1], TPR[1], _ = roc_curve(y_test, Y_score)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Hurricane Predictor', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GRidsearch\n",
    "logreg_parameters = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,1,50),\n",
    "    'solver':['liblinear']\n",
    "}\n",
    "modelgs = LogisticRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=modelgs,\n",
    "                          param_grid=logreg_parameters,   \n",
    "                          cv=5) \n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.fit(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.score(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for final grid-search model\n",
    "\n",
    "gspredict = grid_search.predict(xgs)\n",
    "confusion_matrix(ygs, gspredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Below i will construct a number of dataframes that I will subsequently run both regression and classification models on.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame(df1.groupby('EVENT_TYPE').CASUALTIES.agg(['count','min', 'max', 'mean', 'sum']).sort_values('sum', axis=0, ascending=False).reset_index().head(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in df1.columns:\n",
    "    print df1[column].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "\n",
    "y = LabelEncoder().fit_transform(df1['is_Hurricane'])\n",
    "x = df1['TOTAL_DEATHS'].reshape(-1,1)\n",
    "model_1 = logmodel.fit(x,y)\n",
    "\n",
    "model_1.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up train and test data for X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data is shuffled\n",
    "# cv = KFold(len(df1),n_folds=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stratified and shuffled these are the ones for train and test set\n",
    "# cv = StratifiedKFold(y, n_folds=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sbn\n",
    "plt.figure(figsize=(11,8))\n",
    "sbn.heatmap(df1.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global_modelswant to build a global dict to store all my models for future use\n",
    "#  = {\n",
    "#             'bdt': BaggingClassifier(DecisionTreeClassifier()), \n",
    "#             'rf': RandomForestClassifier(class_weight='balanced', n_jobs=-1),\n",
    "#             'et': ExtraTreesClassifier(class_weight='balanced', n_jobs=-1)\n",
    "# }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_models = {\n",
    "   'knn' : KNeighborsClassifier(),\n",
    "   'knn_bag' : BaggingClassifier(KNeighborsClassifier()),\n",
    "   'logreg' : LogisticRegression(),\n",
    "   'logreg_bag' : BaggingClassifier(LogisticRegression()),\n",
    "   'tree' : DecisionTreeClassifier(),\n",
    "   'tree_bag' : BaggingClassifier(DecisionTreeClassifier()),\n",
    "   'forest' : RandomForestClassifier(),\n",
    "   'forest_bag' : BaggingClassifier(RandomForestClassifier()),\n",
    "   'extra_tree' : ExtraTreesClassifier(),\n",
    "   'extra_tree_bag' : BaggingClassifier(ExtraTreesClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def evaluate_model(X_train, X_test, \n",
    "                   y_train, y_test,\n",
    "                  model):\n",
    "    pick_a_model = global_models[model]\n",
    "    pick_a_model.fit(X_train, y_train)\n",
    "    print 'train model score:', pick_a_model.score(X_train, y_train)\n",
    "    predictions = pick_a_model.predict(X_test)\n",
    "    print '\\nconfusion matrix: \\n\\n', confusion_matrix(y_test, predictions)\n",
    "    print '\\nclassification report: \\n\\n', classification_report(y_test, predictions)\n",
    "    results.update({model: pick_a_model.score(X_test, y_test)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in global_models:\n",
    "    evaluate_model(X_train, X_test, y_train, y_test, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 Most Combined Damage: CALIFORNIA\t2006\tJanuary\tFlood\n",
    "CD1 = df1.groupby('EPISODE_ID').COMBINED_DAMAGE.agg(['count','min', 'max', 'mean', 'sum']).sort_values('sum', axis=0, ascending=False).reset_index().head(11)\n",
    "CD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MOST INJURIES- #1 TEXAS\t1998\tOctober\tFlood\tThe Great October Flood\n",
    "I1 = df1.groupby('EPISODE_ID').TOTAL_INJURIES.agg(['count','min', 'max', 'mean', 'sum']).sort_values('sum', axis=0, ascending=False).reset_index().head(11)\n",
    "I1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 TOTAL_DEATHS: MISSOURI\t2011\tMay\tTornado - A strong upper level trough across the central..\n",
    "D1 = df1.groupby('EPISODE_ID').TOTAL_DEATHS.agg(['count','min', 'max', 'mean', 'sum']).sort_values('sum', axis=0, ascending=False).reset_index().head(11)\n",
    "D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Most Casualties- #1 TEXAS\t1998\tOctober\tFlood\tThe Great October Flood\n",
    "\n",
    "X1 = df1.groupby('EPISODE_ID').CASUALTIES.agg(['count','min', 'max', 'mean', 'sum']).sort_values('sum', axis=0, ascending=False).reset_index().head(11)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 TEXAS\t1998\tOctober\tFlood\tThe Great October Flood\n",
    "df1[df1.EPISODE_ID == 1150299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2 TEXAS\t2008\tSeptember\tHurricane IKE - The eye of Hurricane Ike moved ashore in Galve...\n",
    "df1[df1.EPISODE_ID == 23202]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#3 ALABAMA\t2011\tApril\tTornado: A powerful storm system crossed the Southeast \n",
    "df1[df1.EPISODE_ID == 50455]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4 MISSOURI\t2011\tMay\tTornado - A strong upper level trough across the central..\n",
    "df1[df1.EPISODE_ID == 49972]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5 \tMISSOURI\t2007\tAugust\tDrought The first and only Heat Wave of the summer sta...\n",
    "df1[df1.EPISODE_ID == 10217]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#6 FLORIDA\t2004\tAugust\tHurricane The collective effects of Hurricane Charley\n",
    "df1[df1.EPISODE_ID == 178038]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#7 TEXAS\t1998\tOctober\tFlood Flooding along the Guadalupe Rive\n",
    "df1[df1.EPISODE_ID == 1150309]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#8 OKLAHOMA\t1999\tMay\tTornado Rocks Oklahoma - A record outbreak of tornadoes struck Oklaho.\n",
    "df1[df1.EPISODE_ID == 82875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#9 TEXAS\t1998\tOctober\tFlood - Flooding along the San Antonio River\n",
    "df1[df1.EPISODE_ID == 70489]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#10 UTAH\t2013\tJanuary\tWinter Storm A rare freezing rain event\n",
    "df1[df1.EPISODE_ID == 71079]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#11 TENNESSEE\t2011\tApril\tWinter Storm\n",
    "df1[df1.EPISODE_ID == 49915]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 \tTEXAS\t1998\tOctober\tFlood\n",
    "df1[df1.EPISODE_ID == 198565].TOTAL_DEATHS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1 = df1.groupby('EVENT_TYPE').CASUALTIES.agg(['max']).sort_values('max', axis=0, ascending=False).reset_index().head(10)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1[(df1.CASUALTIES == 2409) & (df1.EVENT_TYPE == 'Hurricane') | \n",
    "    (df1.CASUALTIES == 1311) & (df1.EVENT_TYPE == 'Tornado') | \n",
    "    (df1.CASUALTIES == 802) & (df1.EVENT_TYPE == 'Flood') |\n",
    "    (df1.CASUALTIES == 521) & (df1.EVENT_TYPE == 'Drought') | \n",
    "    (df1.CASUALTIES == 300) & (df1.EVENT_TYPE == 'Winter Storm') | \n",
    "    (df1.CASUALTIES == 180) & (df1.EVENT_TYPE == 'Tsunami') | \n",
    "    (df1.CASUALTIES == 104) & (df1.EVENT_TYPE == 'Wildfire') | \n",
    "    (df1.CASUALTIES == 101) & (df1.EVENT_TYPE == 'High Wind')       \n",
    "   ].sort_values('CASUALTIES', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1 = df1.groupby('EVENT_TYPE').TOTAL_DEATHS.agg(['max']).sort_values('max', axis=0, ascending=False).reset_index().head(10)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1[(df1.TOTAL_DEATHS == 161) & (df1.EVENT_TYPE == 'Tornado') | \n",
    "    (df1.TOTAL_DEATHS == 93) & (df1.EVENT_TYPE == 'Drought') | \n",
    "    (df1.TOTAL_DEATHS == 32) & (df1.EVENT_TYPE == 'Tsunami') |\n",
    "    (df1.TOTAL_DEATHS == 23) & (df1.EVENT_TYPE == 'Flood') | \n",
    "    (df1.TOTAL_DEATHS == 22) & (df1.EVENT_TYPE == 'Tropical Storm') | \n",
    "    (df1.TOTAL_DEATHS == 19) & (df1.EVENT_TYPE == 'Heavy Rain') | \n",
    "    (df1.TOTAL_DEATHS == 19) & (df1.EVENT_TYPE == 'Wildfire') \n",
    "   ].sort_values('TOTAL_DEATHS', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1 = df1.groupby('EVENT_TYPE').TOTAL_INJURIES.agg(['max']).sort_values('max', axis=0, ascending=False).reset_index().head(10)\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1[(df1.TOTAL_INJURIES == 2400) & (df1.EVENT_TYPE == 'Hurricane') | \n",
    "    (df1.TOTAL_INJURIES == 1150) & (df1.EVENT_TYPE == 'Tornado') | \n",
    "    (df1.TOTAL_INJURIES == 800) & (df1.EVENT_TYPE == 'Flood') |\n",
    "    (df1.TOTAL_INJURIES == 519) & (df1.EVENT_TYPE == 'Drought') | \n",
    "    (df1.TOTAL_INJURIES == 300) & (df1.EVENT_TYPE == 'Winter Storm') | \n",
    "    (df1.TOTAL_INJURIES == 154) & (df1.EVENT_TYPE == 'Tropical Storm') | \n",
    "    (df1.TOTAL_INJURIES == 100) & (df1.EVENT_TYPE == 'High Wind') |\n",
    "    (df1.TOTAL_INJURIES == 148) & (df1.EVENT_TYPE == 'Tsunami') | \n",
    "    (df1.TOTAL_INJURIES == 90) & (df1.EVENT_TYPE == 'Wildfire') \n",
    "   ].sort_values('TOTAL_INJURIES', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = df1.groupby('EVENT_TYPE').DAMAGE_PROPERTY.agg(['max']).sort_values('max', axis=0, ascending=False).reset_index().head(10)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1[(df1.DAMAGE_PROPERTY == 1.150000e+11) & (df1.EVENT_TYPE == 'Flood') | \n",
    "    (df1.DAMAGE_PROPERTY == 1.790000e+10) & (df1.EVENT_TYPE == 'Rip Current') | \n",
    "    (df1.DAMAGE_PROPERTY == 1.000000e+10) & (df1.EVENT_TYPE == 'Hurricane') |\n",
    "    (df1.DAMAGE_PROPERTY == 2.800000e+09) & (df1.EVENT_TYPE == 'Tornado') | \n",
    "    (df1.DAMAGE_PROPERTY == 1.800000e+09) & (df1.EVENT_TYPE == 'Winter Storm') | \n",
    "    (df1.DAMAGE_PROPERTY == 1.500000e+09) & (df1.EVENT_TYPE == 'High Wind') | \n",
    "    (df1.DAMAGE_PROPERTY == 1.500000e+09) & (df1.EVENT_TYPE == 'WildFire') |\n",
    "    (df1.DAMAGE_PROPERTY == 2.500000e+08) & (df1.EVENT_TYPE == 'Drought') | \n",
    "    (df1.DAMAGE_PROPERTY == 8.100000e+07) & (df1.EVENT_TYPE == 'Tsunami') \n",
    "   ].sort_values('DAMAGE_PROPERTY', axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
