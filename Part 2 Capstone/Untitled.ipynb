{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'train_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5137a0e9884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mall_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-d5137a0e9884>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_data.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_label.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_data.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'train_data.npy'"
     ]
    }
   ],
   "source": [
    "# Blender\n",
    "# Takes the train/test data/label from FeatureEngineer.py\n",
    "# Runs the base models on 80% of the data, trains a logistic regression blender on the remaining 20%\n",
    "# Retrains the base models on 100% of the data and combines the results with the blender\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# models\n",
    "KBEST = 400\n",
    "NAMES = [\"RF\",\"LR\",\"ET\"]\n",
    "MODELS = \t[\n",
    "\t\t\tRandomForestClassifier(max_depth=10, n_estimators=100, max_features=10, criterion='entropy', random_state=1),\n",
    "\t\t\tLogisticRegression(C=15),\n",
    "\t\t\tExtraTreesClassifier(max_depth=10, n_estimators=100, max_features=10, criterion='entropy', random_state=1)\n",
    "\t\t\t]\n",
    "\t\t\t\n",
    "def main():\n",
    "\t\n",
    "\tall_start = time.clock()\n",
    "\n",
    "\t# load data\n",
    "\tX = np.load(\"train_data.npy\")\n",
    "\ty = np.ravel(np.load(\"train_label.npy\"))\n",
    "\tX_test = np.load(\"test_data.npy\")\n",
    "\ttest_label = np.load(\"test_label.npy\")\n",
    "\t\n",
    "\t# select KBest\n",
    "\tselector = SelectKBest(f_classif, k=KBEST)\n",
    "\tX = selector.fit_transform(X, y)\n",
    "\tX_test = selector.transform(X_test)\n",
    "\n",
    "\t# split data into train and validation\n",
    "\tX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\t\n",
    "\t### TRAIN MODELS ON 80% OF THE DATA ###\n",
    "\t\n",
    "\t# prediction holders\n",
    "\tVAL_LIST = []\n",
    "\t\n",
    "\tfor MODEL in MODELS:\n",
    "\t\t\n",
    "\t\tprint MODEL\n",
    "\t\t\n",
    "\t\tstart = time.clock()\n",
    "\t\t\n",
    "\t\t# fit on train and predict validation and test\n",
    "\t\tMODEL.fit(X_train, y_train)\n",
    "\t\ty_val_pred = MODEL.predict_proba(X_val)\n",
    "\t\t\n",
    "\t\tprint \" - \" + str(log_loss(y_val, y_val_pred, eps=1e-15, normalize=True))\n",
    "\t\t\n",
    "\t\t# save validation\n",
    "\t\tVAL_LIST.append(y_val_pred[:,1])\n",
    "\t\t\n",
    "\t\tprint \"   - \" + str(math.floor(time.clock() - start))\n",
    "\t\t\n",
    "\t# combine models\n",
    "\tval_data = np.column_stack(tuple(VAL_LIST))\n",
    "\t\n",
    "\t#######################################\n",
    "\t\n",
    "\t# create and fit blending model\n",
    "\tmodel = LogisticRegression(C=15)\n",
    "\tmodel.fit(val_data, y_val)\n",
    "\t\n",
    "\t### RETRAIN MODELS ON 100% OF THE DATA ###\n",
    "\t\n",
    "\t# prediction holders\n",
    "\tTEST_LIST = []\n",
    "\t\n",
    "\tfor NAME,MODEL in zip(NAMES,MODELS):\n",
    "\t\t\n",
    "\t\tprint MODEL\n",
    "\t\t\n",
    "\t\tstart = time.clock()\n",
    "\t\t\n",
    "\t\t# fit on train and predict validation and test\n",
    "\t\tMODEL.fit(X, y)\n",
    "\t\ty_test_pred = MODEL.predict_proba(X_test)\n",
    "\t\t\t\t\n",
    "\t\t# save\n",
    "\t\tTEST_LIST.append(y_test_pred[:,1])\n",
    "\t\t\n",
    "\t\t# save result to file\n",
    "\t\tdata = np.transpose(np.vstack((np.ravel(test_label), y_test_pred[:,1])))\n",
    "\t\tnp.savetxt(NAME+'.csv', data, fmt='%d,%f', header='ID,PredictedProb', delimiter=',', comments='')\n",
    "\t\n",
    "\t\tprint \"   - \" + str(math.floor(time.clock() - start))\n",
    "\t\t\n",
    "\t# combine models\n",
    "\ttest_data = np.column_stack(tuple(TEST_LIST))\n",
    "\t\n",
    "\t##########################################\n",
    "\t\n",
    "\t# predict and save result\n",
    "\tpredicted_label = model.predict_proba(test_data)\n",
    "\tdata = np.transpose(np.vstack((np.ravel(test_label), predicted_label[:,1])))\n",
    "\tnp.savetxt('results_blender.csv', data, fmt='%d,%f', header='ID,PredictedProb', delimiter=',', comments='')\n",
    "\t\n",
    "\t# print\n",
    "\tprint model.intercept_\n",
    "\tprint model.coef_\n",
    "\tprint time.clock() - all_start\n",
    "\t\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
