{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('../Part 2 Capstone/df2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['MONTH_NAME'] = df1['MONTH_NAME'].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_types = ['Drought' ,'Flood' ,'Winter Storm', 'OTHER', 'High Wind' ,'ThunderStorm',\n",
    " 'Wildfire', 'Rip Current' ,'Tropical Storm' ,'Tornado' ,'Hurricane', 'Tsunami',\n",
    " 'Landslide']\n",
    "for i in event_types:\n",
    "     df1['is_'+i] = df1['EVENT_TYPE'].apply(lambda x: 1 if i in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'F1', 'F0', 'F2', 'F3', 'F4', 'EF3', 'EF1', 'EF0', 'EF2',\n",
       "       'EF4', 'EF5'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.TOR_F_SCALE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tor_all = pd.get_dummies(df1.TOR_F_SCALE, prefix=\"is\", prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "tor_all_1 = pd.get_dummies(df1.STATE, prefix=\"is\", prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_ALABAMA</th>\n",
       "      <th>is_ALASKA</th>\n",
       "      <th>is_AMERICAN SAMOA</th>\n",
       "      <th>is_ARIZONA</th>\n",
       "      <th>is_ARKANSAS</th>\n",
       "      <th>is_ATLANTIC NORTH</th>\n",
       "      <th>is_ATLANTIC SOUTH</th>\n",
       "      <th>is_CALIFORNIA</th>\n",
       "      <th>is_COLORADO</th>\n",
       "      <th>is_CONNECTICUT</th>\n",
       "      <th>...</th>\n",
       "      <th>is_TENNESSEE</th>\n",
       "      <th>is_TEXAS</th>\n",
       "      <th>is_UTAH</th>\n",
       "      <th>is_VERMONT</th>\n",
       "      <th>is_VIRGIN ISLANDS</th>\n",
       "      <th>is_VIRGINIA</th>\n",
       "      <th>is_WASHINGTON</th>\n",
       "      <th>is_WEST VIRGINIA</th>\n",
       "      <th>is_WISCONSIN</th>\n",
       "      <th>is_WYOMING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_ALABAMA  is_ALASKA  is_AMERICAN SAMOA  is_ARIZONA  is_ARKANSAS  \\\n",
       "0         0.0        0.0                0.0         0.0          0.0   \n",
       "1         0.0        0.0                0.0         0.0          0.0   \n",
       "2         0.0        0.0                0.0         0.0          0.0   \n",
       "3         0.0        0.0                0.0         0.0          0.0   \n",
       "4         0.0        0.0                0.0         0.0          0.0   \n",
       "\n",
       "   is_ATLANTIC NORTH  is_ATLANTIC SOUTH  is_CALIFORNIA  is_COLORADO  \\\n",
       "0                0.0                0.0            0.0          1.0   \n",
       "1                0.0                0.0            0.0          0.0   \n",
       "2                0.0                0.0            0.0          0.0   \n",
       "3                0.0                0.0            0.0          0.0   \n",
       "4                0.0                0.0            0.0          0.0   \n",
       "\n",
       "   is_CONNECTICUT     ...      is_TENNESSEE  is_TEXAS  is_UTAH  is_VERMONT  \\\n",
       "0             0.0     ...               0.0       0.0      0.0         0.0   \n",
       "1             0.0     ...               0.0       1.0      0.0         0.0   \n",
       "2             0.0     ...               0.0       1.0      0.0         0.0   \n",
       "3             0.0     ...               0.0       1.0      0.0         0.0   \n",
       "4             0.0     ...               0.0       1.0      0.0         0.0   \n",
       "\n",
       "   is_VIRGIN ISLANDS  is_VIRGINIA  is_WASHINGTON  is_WEST VIRGINIA  \\\n",
       "0                0.0          0.0            0.0               0.0   \n",
       "1                0.0          0.0            0.0               0.0   \n",
       "2                0.0          0.0            0.0               0.0   \n",
       "3                0.0          0.0            0.0               0.0   \n",
       "4                0.0          0.0            0.0               0.0   \n",
       "\n",
       "   is_WISCONSIN  is_WYOMING  \n",
       "0           0.0         0.0  \n",
       "1           0.0         0.0  \n",
       "2           0.0         0.0  \n",
       "3           0.0         0.0  \n",
       "4           0.0         0.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tor_all.head()\n",
    "tor_all_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['TD'] = df1['TOTAL_DEATHS'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['TI'] = df1['TOTAL_INJURIES'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    654313.000000\n",
       "mean          0.010668\n",
       "std           0.102732\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max           1.000000\n",
       "Name: TI, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['TI'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df1, tor_all_1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>TOTAL_INJURIES</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>DEATHS_INDIRECT</th>\n",
       "      <th>TOTAL_DEATHS</th>\n",
       "      <th>CASUALTIES</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>...</th>\n",
       "      <th>is_TENNESSEE</th>\n",
       "      <th>is_TEXAS</th>\n",
       "      <th>is_UTAH</th>\n",
       "      <th>is_VERMONT</th>\n",
       "      <th>is_VIRGIN ISLANDS</th>\n",
       "      <th>is_VIRGINIA</th>\n",
       "      <th>is_WASHINGTON</th>\n",
       "      <th>is_WEST VIRGINIA</th>\n",
       "      <th>is_WISCONSIN</th>\n",
       "      <th>is_WYOMING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.543130e+05</td>\n",
       "      <td>6.543130e+05</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>6.543130e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.892418e+06</td>\n",
       "      <td>8.729241e+04</td>\n",
       "      <td>0.053577</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.066960</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>0.077839</td>\n",
       "      <td>3.812313e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023927</td>\n",
       "      <td>0.069227</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.028853</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.023666</td>\n",
       "      <td>0.010217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.418225e+06</td>\n",
       "      <td>7.913208e+04</td>\n",
       "      <td>2.914238</td>\n",
       "      <td>3.024913</td>\n",
       "      <td>4.203051</td>\n",
       "      <td>0.284431</td>\n",
       "      <td>0.062737</td>\n",
       "      <td>0.297602</td>\n",
       "      <td>4.334101</td>\n",
       "      <td>3.506985e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152823</td>\n",
       "      <td>0.253840</td>\n",
       "      <td>0.079463</td>\n",
       "      <td>0.081423</td>\n",
       "      <td>0.016445</td>\n",
       "      <td>0.167394</td>\n",
       "      <td>0.071041</td>\n",
       "      <td>0.107334</td>\n",
       "      <td>0.152007</td>\n",
       "      <td>0.100561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.419000e+03</td>\n",
       "      <td>7.650000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.808540e+05</td>\n",
       "      <td>3.058300e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.533630e+05</td>\n",
       "      <td>5.888900e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.371730e+06</td>\n",
       "      <td>1.625420e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.535308e+06</td>\n",
       "      <td>1.152422e+06</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>1.790000e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           EVENT_ID    EPISODE_ID  INJURIES_DIRECT  INJURIES_INDIRECT  \\\n",
       "count  6.543130e+05  6.543130e+05    654313.000000      654313.000000   \n",
       "mean   1.892418e+06  8.729241e+04         0.053577           0.013384   \n",
       "std    2.418225e+06  7.913208e+04         2.914238           3.024913   \n",
       "min    3.419000e+03  7.650000e+02         0.000000           0.000000   \n",
       "25%    1.808540e+05  3.058300e+04         0.000000           0.000000   \n",
       "50%    3.533630e+05  5.888900e+04         0.000000           0.000000   \n",
       "75%    5.371730e+06  1.625420e+05         0.000000           0.000000   \n",
       "max    5.535308e+06  1.152422e+06      1150.000000        2400.000000   \n",
       "\n",
       "       TOTAL_INJURIES  DEATHS_DIRECT  DEATHS_INDIRECT   TOTAL_DEATHS  \\\n",
       "count   654313.000000  654313.000000    654313.000000  654313.000000   \n",
       "mean         0.066960       0.008861         0.002017       0.010879   \n",
       "std          4.203051       0.284431         0.062737       0.297602   \n",
       "min          0.000000       0.000000         0.000000       0.000000   \n",
       "25%          0.000000       0.000000         0.000000       0.000000   \n",
       "50%          0.000000       0.000000         0.000000       0.000000   \n",
       "75%          0.000000       0.000000         0.000000       0.000000   \n",
       "max       2400.000000     158.000000        11.000000     161.000000   \n",
       "\n",
       "          CASUALTIES  DAMAGE_PROPERTY      ...         is_TENNESSEE  \\\n",
       "count  654313.000000     6.543130e+05      ...        654313.000000   \n",
       "mean        0.077839     3.812313e+05      ...             0.023927   \n",
       "std         4.334101     3.506985e+07      ...             0.152823   \n",
       "min         0.000000     0.000000e+00      ...             0.000000   \n",
       "25%         0.000000     0.000000e+00      ...             0.000000   \n",
       "50%         0.000000     0.000000e+00      ...             0.000000   \n",
       "75%         0.000000     0.000000e+00      ...             0.000000   \n",
       "max      2409.000000     1.790000e+10      ...             1.000000   \n",
       "\n",
       "            is_TEXAS        is_UTAH     is_VERMONT  is_VIRGIN ISLANDS  \\\n",
       "count  654313.000000  654313.000000  654313.000000      654313.000000   \n",
       "mean        0.069227       0.006355       0.006674           0.000271   \n",
       "std         0.253840       0.079463       0.081423           0.016445   \n",
       "min         0.000000       0.000000       0.000000           0.000000   \n",
       "25%         0.000000       0.000000       0.000000           0.000000   \n",
       "50%         0.000000       0.000000       0.000000           0.000000   \n",
       "75%         0.000000       0.000000       0.000000           0.000000   \n",
       "max         1.000000       1.000000       1.000000           1.000000   \n",
       "\n",
       "         is_VIRGINIA  is_WASHINGTON  is_WEST VIRGINIA   is_WISCONSIN  \\\n",
       "count  654313.000000  654313.000000     654313.000000  654313.000000   \n",
       "mean        0.028853       0.005072          0.011657       0.023666   \n",
       "std         0.167394       0.071041          0.107334       0.152007   \n",
       "min         0.000000       0.000000          0.000000       0.000000   \n",
       "25%         0.000000       0.000000          0.000000       0.000000   \n",
       "50%         0.000000       0.000000          0.000000       0.000000   \n",
       "75%         0.000000       0.000000          0.000000       0.000000   \n",
       "max         1.000000       1.000000          1.000000       1.000000   \n",
       "\n",
       "          is_WYOMING  \n",
       "count  654313.000000  \n",
       "mean        0.010217  \n",
       "std         0.100561  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 99 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_all_model = df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>TOTAL_INJURIES</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>DEATHS_INDIRECT</th>\n",
       "      <th>TOTAL_DEATHS</th>\n",
       "      <th>CASUALTIES</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>...</th>\n",
       "      <th>is_TENNESSEE</th>\n",
       "      <th>is_TEXAS</th>\n",
       "      <th>is_UTAH</th>\n",
       "      <th>is_VERMONT</th>\n",
       "      <th>is_VIRGIN ISLANDS</th>\n",
       "      <th>is_VIRGINIA</th>\n",
       "      <th>is_WASHINGTON</th>\n",
       "      <th>is_WEST VIRGINIA</th>\n",
       "      <th>is_WISCONSIN</th>\n",
       "      <th>is_WYOMING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.543130e+05</td>\n",
       "      <td>6.543130e+05</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>6.543130e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "      <td>654313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.892418e+06</td>\n",
       "      <td>8.729241e+04</td>\n",
       "      <td>0.053577</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.066960</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>0.077839</td>\n",
       "      <td>3.812313e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023927</td>\n",
       "      <td>0.069227</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.028853</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.023666</td>\n",
       "      <td>0.010217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.418225e+06</td>\n",
       "      <td>7.913208e+04</td>\n",
       "      <td>2.914238</td>\n",
       "      <td>3.024913</td>\n",
       "      <td>4.203051</td>\n",
       "      <td>0.284431</td>\n",
       "      <td>0.062737</td>\n",
       "      <td>0.297602</td>\n",
       "      <td>4.334101</td>\n",
       "      <td>3.506985e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152823</td>\n",
       "      <td>0.253840</td>\n",
       "      <td>0.079463</td>\n",
       "      <td>0.081423</td>\n",
       "      <td>0.016445</td>\n",
       "      <td>0.167394</td>\n",
       "      <td>0.071041</td>\n",
       "      <td>0.107334</td>\n",
       "      <td>0.152007</td>\n",
       "      <td>0.100561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.419000e+03</td>\n",
       "      <td>7.650000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.808540e+05</td>\n",
       "      <td>3.058300e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.533630e+05</td>\n",
       "      <td>5.888900e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.371730e+06</td>\n",
       "      <td>1.625420e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.535308e+06</td>\n",
       "      <td>1.152422e+06</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>1.790000e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           EVENT_ID    EPISODE_ID  INJURIES_DIRECT  INJURIES_INDIRECT  \\\n",
       "count  6.543130e+05  6.543130e+05    654313.000000      654313.000000   \n",
       "mean   1.892418e+06  8.729241e+04         0.053577           0.013384   \n",
       "std    2.418225e+06  7.913208e+04         2.914238           3.024913   \n",
       "min    3.419000e+03  7.650000e+02         0.000000           0.000000   \n",
       "25%    1.808540e+05  3.058300e+04         0.000000           0.000000   \n",
       "50%    3.533630e+05  5.888900e+04         0.000000           0.000000   \n",
       "75%    5.371730e+06  1.625420e+05         0.000000           0.000000   \n",
       "max    5.535308e+06  1.152422e+06      1150.000000        2400.000000   \n",
       "\n",
       "       TOTAL_INJURIES  DEATHS_DIRECT  DEATHS_INDIRECT   TOTAL_DEATHS  \\\n",
       "count   654313.000000  654313.000000    654313.000000  654313.000000   \n",
       "mean         0.066960       0.008861         0.002017       0.010879   \n",
       "std          4.203051       0.284431         0.062737       0.297602   \n",
       "min          0.000000       0.000000         0.000000       0.000000   \n",
       "25%          0.000000       0.000000         0.000000       0.000000   \n",
       "50%          0.000000       0.000000         0.000000       0.000000   \n",
       "75%          0.000000       0.000000         0.000000       0.000000   \n",
       "max       2400.000000     158.000000        11.000000     161.000000   \n",
       "\n",
       "          CASUALTIES  DAMAGE_PROPERTY      ...         is_TENNESSEE  \\\n",
       "count  654313.000000     6.543130e+05      ...        654313.000000   \n",
       "mean        0.077839     3.812313e+05      ...             0.023927   \n",
       "std         4.334101     3.506985e+07      ...             0.152823   \n",
       "min         0.000000     0.000000e+00      ...             0.000000   \n",
       "25%         0.000000     0.000000e+00      ...             0.000000   \n",
       "50%         0.000000     0.000000e+00      ...             0.000000   \n",
       "75%         0.000000     0.000000e+00      ...             0.000000   \n",
       "max      2409.000000     1.790000e+10      ...             1.000000   \n",
       "\n",
       "            is_TEXAS        is_UTAH     is_VERMONT  is_VIRGIN ISLANDS  \\\n",
       "count  654313.000000  654313.000000  654313.000000      654313.000000   \n",
       "mean        0.069227       0.006355       0.006674           0.000271   \n",
       "std         0.253840       0.079463       0.081423           0.016445   \n",
       "min         0.000000       0.000000       0.000000           0.000000   \n",
       "25%         0.000000       0.000000       0.000000           0.000000   \n",
       "50%         0.000000       0.000000       0.000000           0.000000   \n",
       "75%         0.000000       0.000000       0.000000           0.000000   \n",
       "max         1.000000       1.000000       1.000000           1.000000   \n",
       "\n",
       "         is_VIRGINIA  is_WASHINGTON  is_WEST VIRGINIA   is_WISCONSIN  \\\n",
       "count  654313.000000  654313.000000     654313.000000  654313.000000   \n",
       "mean        0.028853       0.005072          0.011657       0.023666   \n",
       "std         0.167394       0.071041          0.107334       0.152007   \n",
       "min         0.000000       0.000000          0.000000       0.000000   \n",
       "25%         0.000000       0.000000          0.000000       0.000000   \n",
       "50%         0.000000       0.000000          0.000000       0.000000   \n",
       "75%         0.000000       0.000000          0.000000       0.000000   \n",
       "max         1.000000       1.000000          1.000000       1.000000   \n",
       "\n",
       "          is_WYOMING  \n",
       "count  654313.000000  \n",
       "mean        0.010217  \n",
       "std         0.100561  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 99 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_all_model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_all_model.drop([ 'YEAR', u'TOTAL_INJURIES', u'DAMAGE_PROPERTY', u'DAMAGE_CROPS',\n",
    "       u'COMBINED_DAMAGE', 'EVENT_ID', u'EPISODE_ID',u'INJURIES_DIRECT', u'CASUALTIES', u'INJURIES_INDIRECT','EVENT_TYPE', 'DATE', u'CZ_NAME', u'CATEGORY', u'STATE',\n",
    "       u'MONTH_NAME', u'TOR_F_SCALE', u'EPISODE_NARRATIVE', u'EVENT_NARRATIVE',u'DEATHS_DIRECT',\n",
    "       u'DEATHS_INDIRECT', u'TOTAL_DEATHS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TOR_LENGTH', u'TOR_WIDTH', u'is_Drought', u'is_Flood',\n",
       "       u'is_Winter Storm', u'is_OTHER', u'is_High Wind', u'is_ThunderStorm',\n",
       "       u'is_Wildfire', u'is_Rip Current', u'is_Tropical Storm', u'is_Tornado',\n",
       "       u'is_Hurricane', u'is_Tsunami', u'is_Landslide', u'TD', u'TI',\n",
       "       u'is_ALABAMA', u'is_ALASKA', u'is_AMERICAN SAMOA', u'is_ARIZONA',\n",
       "       u'is_ARKANSAS', u'is_ATLANTIC NORTH', u'is_ATLANTIC SOUTH',\n",
       "       u'is_CALIFORNIA', u'is_COLORADO', u'is_CONNECTICUT', u'is_DELAWARE',\n",
       "       u'is_DISTRICT OF COLUMBIA', u'is_E PACIFIC', u'is_FLORIDA',\n",
       "       u'is_GEORGIA', u'is_GUAM', u'is_GULF OF ALASKA', u'is_GULF OF MEXICO',\n",
       "       u'is_HAWAII', u'is_HAWAII WATERS', u'is_IDAHO', u'is_ILLINOIS',\n",
       "       u'is_INDIANA', u'is_IOWA', u'is_KANSAS', u'is_KENTUCKY',\n",
       "       u'is_LAKE ERIE', u'is_LAKE HURON', u'is_LAKE MICHIGAN',\n",
       "       u'is_LAKE ONTARIO', u'is_LAKE ST CLAIR', u'is_LAKE SUPERIOR',\n",
       "       u'is_LOUISIANA', u'is_MAINE', u'is_MARYLAND', u'is_MASSACHUSETTS',\n",
       "       u'is_MICHIGAN', u'is_MINNESOTA', u'is_MISSISSIPPI', u'is_MISSOURI',\n",
       "       u'is_MONTANA', u'is_NEBRASKA', u'is_NEVADA', u'is_NEW HAMPSHIRE',\n",
       "       u'is_NEW JERSEY', u'is_NEW MEXICO', u'is_NEW YORK',\n",
       "       u'is_NORTH CAROLINA', u'is_NORTH DAKOTA', u'is_OHIO', u'is_OKLAHOMA',\n",
       "       u'is_OREGON', u'is_PENNSYLVANIA', u'is_PUERTO RICO', u'is_RHODE ISLAND',\n",
       "       u'is_SOUTH CAROLINA', u'is_SOUTH DAKOTA', u'is_ST LAWRENCE R',\n",
       "       u'is_TENNESSEE', u'is_TEXAS', u'is_UTAH', u'is_VERMONT',\n",
       "       u'is_VIRGIN ISLANDS', u'is_VIRGINIA', u'is_WASHINGTON',\n",
       "       u'is_WEST VIRGINIA', u'is_WISCONSIN', u'is_WYOMING'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_all_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99070628277292361"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "y1 = LabelEncoder().fit_transform(is_all_model['TI'])\n",
    "x1 = is_all_model.drop(['TI','TD'], axis=1)\n",
    "\n",
    "model1 = rf_model.fit(x1,y1)\n",
    "model1.score(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[647301,     32],\n",
       "       [  6049,    931]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class1 = model1.predict(x1)\n",
    "confusion_matrix(y1, predicted_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00    647333\n",
      "          1       0.97      0.13      0.23      6980\n",
      "\n",
      "avg / total       0.99      0.99      0.99    654313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y1, predicted_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(11,8))\n",
    "# sbn.heatmap(is_tornado_model.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((490734, 83), (163579, 83), (490734,), (163579,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfTTS = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99068538148976837"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTTS = rfTTS.fit(x_train, y_train)\n",
    "\n",
    "modelTTS.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[485462,     25],\n",
       "       [  4546,    701]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train = modelTTS.predict(x_train)\n",
    "confusion_matrix(y_train, predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9889961425366337"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTTS.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[161720,    126],\n",
       "       [  1674,     59]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = modelTTS.predict(x_test)\n",
    "confusion_matrix(y_test, predict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Y_score = rfTTS.decision_function(x_test)\n",
    "\n",
    "# FPR = dict()\n",
    "# TPR = dict()\n",
    "# ROC_AUC = dict()\n",
    "\n",
    "# print roc_curve(y_test, Y_score)\n",
    "\n",
    "# FPR[1], TPR[1], _ = roc_curve(y_test, Y_score)\n",
    "# ROC_AUC[1] = auc(FPR[1], TPR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[11,9])\n",
    "# plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "# plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate', fontsize=18)\n",
    "# plt.ylabel('True Positive Rate', fontsize=18)\n",
    "# plt.title('Tornado Deaths Predictor', fontsize=18)\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #GRidsearch\n",
    "# rf_parameters = {\n",
    "#     \"n_estimators\" : [10, 25, 50, 100, 500],\n",
    "#     \"max_depth\" : [2,3,5,7,10, None],\n",
    "#     \"max_features\" : [0.25, 0.5, 0.75, 1.0]\n",
    "# }\n",
    "# modelgs = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search = GridSearchCV(estimator=modelgs,\n",
    "#                           param_grid=rf_parameters\n",
    "#                            , n_jobs=-1) \n",
    "# grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ygs = LabelEncoder().fit_transform(y_test)\n",
    "# xgs = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search.fit(xgs, ygs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search.best_estimator_.fit(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search.best_estimator_.score(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for final grid-search model\n",
    "\n",
    "# gspredict = grid_search.predict(xgs)\n",
    "# confusion_matrix(ygs, gspredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = is_all_model.sample(frac=0.1)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOR_LENGTH</th>\n",
       "      <th>TOR_WIDTH</th>\n",
       "      <th>is_Drought</th>\n",
       "      <th>is_Flood</th>\n",
       "      <th>is_Winter Storm</th>\n",
       "      <th>is_OTHER</th>\n",
       "      <th>is_High Wind</th>\n",
       "      <th>is_ThunderStorm</th>\n",
       "      <th>is_Wildfire</th>\n",
       "      <th>is_Rip Current</th>\n",
       "      <th>...</th>\n",
       "      <th>is_TENNESSEE</th>\n",
       "      <th>is_TEXAS</th>\n",
       "      <th>is_UTAH</th>\n",
       "      <th>is_VERMONT</th>\n",
       "      <th>is_VIRGIN ISLANDS</th>\n",
       "      <th>is_VIRGINIA</th>\n",
       "      <th>is_WASHINGTON</th>\n",
       "      <th>is_WEST VIRGINIA</th>\n",
       "      <th>is_WISCONSIN</th>\n",
       "      <th>is_WYOMING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "      <td>65431.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.073482</td>\n",
       "      <td>3.492652</td>\n",
       "      <td>0.070303</td>\n",
       "      <td>0.108022</td>\n",
       "      <td>0.409332</td>\n",
       "      <td>0.009965</td>\n",
       "      <td>0.044887</td>\n",
       "      <td>0.308325</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023552</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>0.006786</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.028152</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.012043</td>\n",
       "      <td>0.024148</td>\n",
       "      <td>0.010316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.447550</td>\n",
       "      <td>43.814567</td>\n",
       "      <td>0.255659</td>\n",
       "      <td>0.310411</td>\n",
       "      <td>0.491714</td>\n",
       "      <td>0.099325</td>\n",
       "      <td>0.207057</td>\n",
       "      <td>0.461805</td>\n",
       "      <td>0.076778</td>\n",
       "      <td>0.034062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151648</td>\n",
       "      <td>0.253826</td>\n",
       "      <td>0.082096</td>\n",
       "      <td>0.081913</td>\n",
       "      <td>0.015636</td>\n",
       "      <td>0.165408</td>\n",
       "      <td>0.073562</td>\n",
       "      <td>0.109080</td>\n",
       "      <td>0.153508</td>\n",
       "      <td>0.101044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TOR_LENGTH     TOR_WIDTH    is_Drought      is_Flood  \\\n",
       "count  65431.000000  65431.000000  65431.000000  65431.000000   \n",
       "mean       0.073482      3.492652      0.070303      0.108022   \n",
       "std        1.447550     43.814567      0.255659      0.310411   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000   \n",
       "max      300.000000   2394.000000      1.000000      1.000000   \n",
       "\n",
       "       is_Winter Storm      is_OTHER  is_High Wind  is_ThunderStorm  \\\n",
       "count     65431.000000  65431.000000  65431.000000     65431.000000   \n",
       "mean          0.409332      0.009965      0.044887         0.308325   \n",
       "std           0.491714      0.099325      0.207057         0.461805   \n",
       "min           0.000000      0.000000      0.000000         0.000000   \n",
       "25%           0.000000      0.000000      0.000000         0.000000   \n",
       "50%           0.000000      0.000000      0.000000         0.000000   \n",
       "75%           1.000000      0.000000      0.000000         1.000000   \n",
       "max           1.000000      1.000000      1.000000         1.000000   \n",
       "\n",
       "        is_Wildfire  is_Rip Current      ...       is_TENNESSEE      is_TEXAS  \\\n",
       "count  65431.000000    65431.000000      ...       65431.000000  65431.000000   \n",
       "mean       0.005930        0.001162      ...           0.023552      0.069218   \n",
       "std        0.076778        0.034062      ...           0.151648      0.253826   \n",
       "min        0.000000        0.000000      ...           0.000000      0.000000   \n",
       "25%        0.000000        0.000000      ...           0.000000      0.000000   \n",
       "50%        0.000000        0.000000      ...           0.000000      0.000000   \n",
       "75%        0.000000        0.000000      ...           0.000000      0.000000   \n",
       "max        1.000000        1.000000      ...           1.000000      1.000000   \n",
       "\n",
       "            is_UTAH    is_VERMONT  is_VIRGIN ISLANDS   is_VIRGINIA  \\\n",
       "count  65431.000000  65431.000000       65431.000000  65431.000000   \n",
       "mean       0.006786      0.006755           0.000245      0.028152   \n",
       "std        0.082096      0.081913           0.015636      0.165408   \n",
       "min        0.000000      0.000000           0.000000      0.000000   \n",
       "25%        0.000000      0.000000           0.000000      0.000000   \n",
       "50%        0.000000      0.000000           0.000000      0.000000   \n",
       "75%        0.000000      0.000000           0.000000      0.000000   \n",
       "max        1.000000      1.000000           1.000000      1.000000   \n",
       "\n",
       "       is_WASHINGTON  is_WEST VIRGINIA  is_WISCONSIN    is_WYOMING  \n",
       "count   65431.000000      65431.000000  65431.000000  65431.000000  \n",
       "mean        0.005441          0.012043      0.024148      0.010316  \n",
       "std         0.073562          0.109080      0.153508      0.101044  \n",
       "min         0.000000          0.000000      0.000000      0.000000  \n",
       "25%         0.000000          0.000000      0.000000      0.000000  \n",
       "50%         0.000000          0.000000      0.000000      0.000000  \n",
       "75%         0.000000          0.000000      0.000000      0.000000  \n",
       "max         1.000000          1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 85 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y1 = LabelEncoder().fit_transform(df['TI'])\n",
    "x1 = df.drop(['TI', 'TD'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45801, 83) (45801,)\n",
      "(19630, 83) (19630,)\n"
     ]
    }
   ],
   "source": [
    "# setting up train and test data for X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(x1, y1, test_size=0.3)\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_models = {\n",
    "   'knn' : KNeighborsClassifier(),\n",
    "   'knn_bag' : BaggingClassifier(KNeighborsClassifier()),\n",
    "   'logreg' : LogisticRegression(),\n",
    "   'logreg_bag' : BaggingClassifier(LogisticRegression()),\n",
    "   'tree' : DecisionTreeClassifier(),\n",
    "   'tree_bag' : BaggingClassifier(DecisionTreeClassifier()),\n",
    "   'extra_tree' : ExtraTreesClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def evaluate_model(X_train, X_test, \n",
    "                   y_train, y_test,\n",
    "                  model):\n",
    "    pick_a_model = global_models[model]\n",
    "    pick_a_model.fit(X_train, y_train)\n",
    "    print 'This is the model:', (model)\n",
    "    print 'Train model score:', pick_a_model.score(X_train, y_train)\n",
    "    predictions = pick_a_model.predict(X_test)\n",
    "    print '\\nConfusion matrix: \\n\\n', confusion_matrix(y_test, predictions)\n",
    "    print '\\nClassification report: \\n\\n', classification_report(y_test, predictions)\n",
    "    results.update({model: pick_a_model.score(X_test, y_test)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the model: knn\n",
      "Train model score: 0.989367044388\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[19419    19]\n",
      " [  187     5]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     19438\n",
      "          1       0.21      0.03      0.05       192\n",
      "\n",
      "avg / total       0.98      0.99      0.99     19630\n",
      "\n",
      "This is the model: logreg_bag\n",
      "Train model score: 0.989432545141\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[19431     7]\n",
      " [  188     4]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     19438\n",
      "          1       0.36      0.02      0.04       192\n",
      "\n",
      "avg / total       0.98      0.99      0.99     19630\n",
      "\n",
      "This is the model: tree_bag\n",
      "Train model score: 0.990895395297\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[19422    16]\n",
      " [  191     1]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     19438\n",
      "          1       0.06      0.01      0.01       192\n",
      "\n",
      "avg / total       0.98      0.99      0.99     19630\n",
      "\n",
      "This is the model: tree\n",
      "Train model score: 0.991201065479\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[19407    31]\n",
      " [  184     8]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     19438\n",
      "          1       0.21      0.04      0.07       192\n",
      "\n",
      "avg / total       0.98      0.99      0.99     19630\n",
      "\n",
      "This is the model: logreg\n",
      "Train model score: 0.989432545141\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[19429     9]\n",
      " [  189     3]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     19438\n",
      "          1       0.25      0.02      0.03       192\n",
      "\n",
      "avg / total       0.98      0.99      0.99     19630\n",
      "\n",
      "This is the model: knn_bag\n",
      "Train model score:"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6423707cb8c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobal_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-15ac57778c3e>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(X_train, X_test, y_train, y_test, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpick_a_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'This is the model:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Train model score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpick_a_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick_a_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\nConfusion matrix: \\n\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mpredicted_probabilitiy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         return self.classes_.take((np.argmax(predicted_probabilitiy, axis=1)),\n\u001b[1;32m    577\u001b[0m                                   axis=0)\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 self.n_classes_)\n\u001b[0;32m--> 621\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/bagging.pyc\u001b[0m in \u001b[0;36m_parallel_predict_proba\u001b[0;34m(estimators, estimators_features, X, n_classes)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimators_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict_proba\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mproba_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/neighbors/classification.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    397\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[1;32m    398\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             )\n\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key in global_models:\n",
    "    evaluate_model(X_train, X_test, y_train, y_test, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "% matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.040\n",
      "Model:                            OLS   Adj. R-squared:                  0.039\n",
      "Method:                 Least Squares   F-statistic:                     33.61\n",
      "Date:                Mon, 12 Dec 2016   Prob (F-statistic):               0.00\n",
      "Time:                        16:37:05   Log-Likelihood:                 58187.\n",
      "No. Observations:               65431   AIC:                        -1.162e+05\n",
      "Df Residuals:                   65349   BIC:                        -1.155e+05\n",
      "Df Model:                          81                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "-------------------------------------------------------------------------------------------\n",
      "TOR_LENGTH                  0.0027      0.000      9.427      0.000         0.002     0.003\n",
      "TOR_WIDTH                   0.0003   1.03e-05     33.014      0.000         0.000     0.000\n",
      "is_Drought                  0.0028      0.003      1.120      0.263        -0.002     0.008\n",
      "is_Flood                   -0.0024      0.002     -1.024      0.306        -0.007     0.002\n",
      "is_Winter Storm            -0.0005      0.002     -0.250      0.802        -0.005     0.004\n",
      "is_OTHER                    0.0267      0.004      6.082      0.000         0.018     0.035\n",
      "is_High Wind                0.0017      0.003      0.608      0.543        -0.004     0.007\n",
      "is_ThunderStorm             0.0093      0.002      4.362      0.000         0.005     0.013\n",
      "is_Wildfire                 0.0599      0.005     11.035      0.000         0.049     0.071\n",
      "is_Rip Current              0.1522      0.012     13.185      0.000         0.130     0.175\n",
      "is_Tropical Storm           0.0019      0.005      0.399      0.690        -0.007     0.011\n",
      "is_Tornado                  0.0048      0.003      1.475      0.140        -0.002     0.011\n",
      "is_Hurricane                0.0477      0.008      5.795      0.000         0.032     0.064\n",
      "is_Tsunami                 -0.0137      0.070     -0.197      0.844        -0.150     0.123\n",
      "is_Landslide                0.0160      0.016      1.012      0.311        -0.015     0.047\n",
      "is_ALABAMA                  0.0097      0.003      2.990      0.003         0.003     0.016\n",
      "is_ALASKA                   0.0074      0.006      1.317      0.188        -0.004     0.018\n",
      "is_AMERICAN SAMOA          -0.0038      0.019     -0.195      0.846        -0.042     0.034\n",
      "is_ARIZONA                  0.0178      0.005      3.583      0.000         0.008     0.028\n",
      "is_ARKANSAS                 0.0020      0.003      0.634      0.526        -0.004     0.008\n",
      "is_ATLANTIC NORTH          -0.0088      0.005     -1.707      0.088        -0.019     0.001\n",
      "is_ATLANTIC SOUTH          -0.0068      0.007     -1.008      0.314        -0.020     0.006\n",
      "is_CALIFORNIA               0.0240      0.004      6.384      0.000         0.017     0.031\n",
      "is_COLORADO                 0.0026      0.003      0.829      0.407        -0.004     0.009\n",
      "is_CONNECTICUT              0.0093      0.007      1.361      0.173        -0.004     0.023\n",
      "is_DELAWARE                 0.0338      0.008      4.478      0.000         0.019     0.049\n",
      "is_DISTRICT OF COLUMBIA    -0.0047      0.019     -0.249      0.803        -0.042     0.033\n",
      "is_E PACIFIC               -0.0048      0.026     -0.189      0.850        -0.055     0.045\n",
      "is_FLORIDA                  0.0299      0.004      8.397      0.000         0.023     0.037\n",
      "is_GEORGIA                  0.0077      0.003      2.504      0.012         0.002     0.014\n",
      "is_GUAM                     0.0454      0.030      1.523      0.128        -0.013     0.104\n",
      "is_GULF OF ALASKA          -0.0074      0.049     -0.150      0.881        -0.104     0.089\n",
      "is_GULF OF MEXICO          -0.0078      0.005     -1.693      0.091        -0.017     0.001\n",
      "is_HAWAII                   0.0035      0.005      0.746      0.455        -0.006     0.013\n",
      "is_HAWAII WATERS           -0.0019      0.098     -0.019      0.985        -0.195     0.191\n",
      "is_IDAHO                   -0.0010      0.006     -0.168      0.867        -0.013     0.011\n",
      "is_ILLINOIS                 0.0040      0.003      1.368      0.171        -0.002     0.010\n",
      "is_INDIANA                  0.0039      0.003      1.201      0.230        -0.002     0.010\n",
      "is_IOWA                     0.0014      0.003      0.505      0.614        -0.004     0.007\n",
      "is_KANSAS                   0.0049      0.003      1.846      0.065        -0.000     0.010\n",
      "is_KENTUCKY                 0.0051      0.003      1.727      0.084        -0.001     0.011\n",
      "is_LAKE ERIE               -0.0085      0.009     -0.905      0.365        -0.027     0.010\n",
      "is_LAKE HURON              -0.0070      0.013     -0.530      0.596        -0.033     0.019\n",
      "is_LAKE MICHIGAN           -0.0081      0.008     -1.006      0.315        -0.024     0.008\n",
      "is_LAKE ONTARIO            -0.0084      0.035     -0.240      0.810        -0.077     0.060\n",
      "is_LAKE ST CLAIR           -0.0077      0.018     -0.433      0.665        -0.043     0.027\n",
      "is_LAKE SUPERIOR           -0.0072      0.014     -0.499      0.618        -0.036     0.021\n",
      "is_LOUISIANA               -0.0024      0.004     -0.582      0.561        -0.010     0.006\n",
      "is_MAINE                   -0.0005      0.005     -0.105      0.916        -0.010     0.009\n",
      "is_MARYLAND                 0.0021      0.004      0.515      0.606        -0.006     0.010\n",
      "is_MASSACHUSETTS            0.0300      0.005      5.758      0.000         0.020     0.040\n",
      "is_MICHIGAN                 0.0084      0.003      2.423      0.015         0.002     0.015\n",
      "is_MINNESOTA                0.0009      0.003      0.284      0.777        -0.005     0.007\n",
      "is_MISSISSIPPI              0.0079      0.003      2.366      0.018         0.001     0.014\n",
      "is_MISSOURI                 0.0111      0.003      3.937      0.000         0.006     0.017\n",
      "is_MONTANA                 -0.0002      0.004     -0.060      0.952        -0.007     0.007\n",
      "is_NEBRASKA                -0.0009      0.003     -0.316      0.752        -0.007     0.005\n",
      "is_NEVADA                   0.0298      0.007      4.514      0.000         0.017     0.043\n",
      "is_NEW HAMPSHIRE            0.0081      0.006      1.303      0.193        -0.004     0.020\n",
      "is_NEW JERSEY               0.0142      0.004      3.776      0.000         0.007     0.022\n",
      "is_NEW MEXICO               0.0028      0.004      0.658      0.510        -0.005     0.011\n",
      "is_NEW YORK                 0.0048      0.003      1.548      0.122        -0.001     0.011\n",
      "is_NORTH CAROLINA           0.0061      0.003      2.046      0.041         0.000     0.012\n",
      "is_NORTH DAKOTA             0.0016      0.004      0.449      0.654        -0.005     0.009\n",
      "is_OHIO                     0.0002      0.003      0.056      0.956        -0.006     0.006\n",
      "is_OKLAHOMA                 0.0041      0.003      1.382      0.167        -0.002     0.010\n",
      "is_OREGON                  -0.0019      0.005     -0.368      0.713        -0.012     0.008\n",
      "is_PENNSYLVANIA             0.0139      0.003      4.393      0.000         0.008     0.020\n",
      "is_PUERTO RICO             -0.0002      0.007     -0.036      0.971        -0.014     0.013\n",
      "is_RHODE ISLAND             0.0092      0.012      0.766      0.444        -0.014     0.033\n",
      "is_SOUTH CAROLINA           0.0009      0.004      0.250      0.803        -0.006     0.008\n",
      "is_SOUTH DAKOTA            -0.0012      0.003     -0.398      0.690        -0.007     0.005\n",
      "is_ST LAWRENCE R           -0.0060      0.057     -0.106      0.916        -0.117     0.105\n",
      "is_TENNESSEE                0.0061      0.003      1.883      0.060        -0.000     0.012\n",
      "is_TEXAS                    0.0048      0.003      1.908      0.056        -0.000     0.010\n",
      "is_UTAH                     0.0064      0.005      1.259      0.208        -0.004     0.016\n",
      "is_VERMONT                  0.0023      0.005      0.450      0.653        -0.008     0.012\n",
      "is_VIRGIN ISLANDS          -0.0127      0.025     -0.513      0.608        -0.061     0.036\n",
      "is_VIRGINIA                 0.0022      0.003      0.715      0.475        -0.004     0.008\n",
      "is_WASHINGTON               0.0256      0.006      4.575      0.000         0.015     0.037\n",
      "is_WEST VIRGINIA            0.0021      0.004      0.524      0.601        -0.006     0.010\n",
      "is_WISCONSIN                0.0030      0.003      0.930      0.352        -0.003     0.009\n",
      "is_WYOMING                  0.0051      0.004      1.181      0.238        -0.003     0.014\n",
      "==============================================================================\n",
      "Omnibus:                    95555.099   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         22016450.489\n",
      "Skew:                           9.215   Prob(JB):                         0.00\n",
      "Kurtosis:                      90.954   Cond. No.                     2.25e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.49e-23. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(y1,x1)    # Describe model\n",
    "res = mod.fit()       # Fit model\n",
    "print res.summary()   # Summarize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## plots ROC curve\n",
    "# def plot_roc(x_test, y_test, model):\n",
    "#     fpr, tpr, _ = roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     print 'ROC AUC: %0.2f' % roc_auc\n",
    "#     plt.figure()\n",
    "#     plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "#     plt.plot([0, 1], [0, 1], 'k--')\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title('ROC Curve')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
