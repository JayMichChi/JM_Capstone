{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              int64\n",
       "BEGIN_YEARMONTH         int64\n",
       "BEGIN_DAY               int64\n",
       "BEGIN_TIME              int64\n",
       "END_YEARMONTH           int64\n",
       "END_DAY                 int64\n",
       "END_TIME                int64\n",
       "EPISODE_ID              int64\n",
       "EVENT_ID                int64\n",
       "STATE                  object\n",
       "STATE_FIPS            float64\n",
       "YEAR                    int64\n",
       "MONTH_NAME             object\n",
       "EVENT_TYPE             object\n",
       "CZ_TYPE                object\n",
       "CZ_FIPS                 int64\n",
       "CZ_NAME                object\n",
       "WFO                    object\n",
       "BEGIN_DATE_TIME        object\n",
       "CZ_TIMEZONE            object\n",
       "END_DATE_TIME          object\n",
       "INJURIES_DIRECT         int64\n",
       "INJURIES_INDIRECT       int64\n",
       "DEATHS_DIRECT           int64\n",
       "DEATHS_INDIRECT         int64\n",
       "DAMAGE_PROPERTY       float64\n",
       "DAMAGE_CROPS          float64\n",
       "SOURCE                 object\n",
       "MAGNITUDE             float64\n",
       "MAGNITUDE_TYPE         object\n",
       "                       ...   \n",
       "TOR_F_SCALE            object\n",
       "TOR_LENGTH            float64\n",
       "TOR_WIDTH             float64\n",
       "TOR_OTHER_WFO          object\n",
       "TOR_OTHER_CZ_STATE     object\n",
       "TOR_OTHER_CZ_FIPS     float64\n",
       "TOR_OTHER_CZ_NAME      object\n",
       "BEGIN_RANGE           float64\n",
       "BEGIN_AZIMUTH          object\n",
       "BEGIN_LOCATION         object\n",
       "END_RANGE             float64\n",
       "END_AZIMUTH            object\n",
       "END_LOCATION           object\n",
       "BEGIN_LAT             float64\n",
       "BEGIN_LON             float64\n",
       "END_LAT               float64\n",
       "END_LON               float64\n",
       "EPISODE_NARRATIVE      object\n",
       "EVENT_NARRATIVE        object\n",
       "LAST_MOD_DATE         float64\n",
       "LAST_MOD_TIME         float64\n",
       "LAST_CERT_DATE        float64\n",
       "LAST_CERT_TIME        float64\n",
       "LAST_MOD               object\n",
       "LAST_CERT              object\n",
       "ADDCORR_FLG           float64\n",
       "ADDCORR_DATE          float64\n",
       "casualties              int64\n",
       "begin_date_full        object\n",
       "Combined_damage       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('../Part 2 Capstone/df1.csv')\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    994039.000000\n",
      "mean      28342.562048\n",
      "std       17292.874500\n",
      "min           0.000000\n",
      "25%       13806.000000\n",
      "50%       27612.000000\n",
      "75%       41418.000000\n",
      "max       79091.000000\n",
      "Name: Unnamed: 0, dtype: float64\n",
      "count    994039.000000\n",
      "mean     200515.128781\n",
      "std         514.703215\n",
      "min      199601.000000\n",
      "25%      200103.000000\n",
      "50%      200512.000000\n",
      "75%      201003.000000\n",
      "max      201310.000000\n",
      "Name: BEGIN_YEARMONTH, dtype: float64\n",
      "count    994039.000000\n",
      "mean         14.891068\n",
      "std           9.178259\n",
      "min           1.000000\n",
      "25%           7.000000\n",
      "50%          15.000000\n",
      "75%          23.000000\n",
      "max          31.000000\n",
      "Name: BEGIN_DAY, dtype: float64\n",
      "count    994039.000000\n",
      "mean       1290.468152\n",
      "std         682.994668\n",
      "min           0.000000\n",
      "25%         800.000000\n",
      "50%        1500.000000\n",
      "75%        1812.000000\n",
      "max        2359.000000\n",
      "Name: BEGIN_TIME, dtype: float64\n",
      "count    994039.000000\n",
      "mean     200515.131411\n",
      "std         514.703310\n",
      "min      199601.000000\n",
      "25%      200103.000000\n",
      "50%      200512.000000\n",
      "75%      201003.000000\n",
      "max      201310.000000\n",
      "Name: END_YEARMONTH, dtype: float64\n",
      "count    994039.000000\n",
      "mean         16.544843\n",
      "std           9.180232\n",
      "min           1.000000\n",
      "25%           9.000000\n",
      "50%          17.000000\n",
      "75%          25.000000\n",
      "max          31.000000\n",
      "Name: END_DAY, dtype: float64\n",
      "count    994039.000000\n",
      "mean       1488.680599\n",
      "std         613.744263\n",
      "min           0.000000\n",
      "25%        1145.000000\n",
      "50%        1615.000000\n",
      "75%        1920.000000\n",
      "max        2359.000000\n",
      "Name: END_TIME, dtype: float64\n",
      "count    9.940390e+05\n",
      "mean     2.144254e+05\n",
      "std      3.316139e+05\n",
      "min      1.000000e+00\n",
      "25%      4.446800e+04\n",
      "50%      8.527700e+04\n",
      "75%      1.758730e+05\n",
      "max      1.152422e+06\n",
      "Name: EPISODE_ID, dtype: float64\n",
      "count    9.940390e+05\n",
      "mean     3.109488e+06\n",
      "std      2.591636e+06\n",
      "min      3.419000e+03\n",
      "25%      2.704935e+05\n",
      "50%      5.177320e+06\n",
      "75%      5.474706e+06\n",
      "max      5.725449e+06\n",
      "Name: EVENT_ID, dtype: float64\n",
      "count     994038\n",
      "unique        68\n",
      "top        TEXAS\n",
      "freq       71871\n",
      "Name: STATE, dtype: object\n",
      "count    994038.000000\n",
      "mean         31.470924\n",
      "std          17.179113\n",
      "min           1.000000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max          99.000000\n",
      "Name: STATE_FIPS, dtype: float64\n",
      "count    994039.000000\n",
      "mean       2005.092126\n",
      "std           5.146791\n",
      "min        1996.000000\n",
      "25%        2001.000000\n",
      "50%        2005.000000\n",
      "75%        2010.000000\n",
      "max        2013.000000\n",
      "Name: YEAR, dtype: float64\n",
      "count        994039\n",
      "unique           23\n",
      "top       June     \n",
      "freq          75806\n",
      "Name: MONTH_NAME, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ugp/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                994039\n",
      "unique                   58\n",
      "top       Thunderstorm Wind\n",
      "freq                 239820\n",
      "Name: EVENT_TYPE, dtype: object\n",
      "count     994039\n",
      "unique         3\n",
      "top            C\n",
      "freq      613750\n",
      "Name: CZ_TYPE, dtype: object\n",
      "count    994039.000000\n",
      "mean         88.600368\n",
      "std         105.526869\n",
      "min           1.000000\n",
      "25%          24.000000\n",
      "50%          61.000000\n",
      "75%         111.000000\n",
      "max         876.000000\n",
      "Name: CZ_FIPS, dtype: float64\n",
      "count         994039\n",
      "unique          6756\n",
      "top       WASHINGTON\n",
      "freq            8277\n",
      "Name: CZ_NAME, dtype: object\n",
      "count     994039\n",
      "unique       125\n",
      "top          PHI\n",
      "freq       27925\n",
      "Name: WFO, dtype: object\n",
      "count                  994039\n",
      "unique                 484427\n",
      "top       07/01/2012 00:00:00\n",
      "freq                     1163\n",
      "Name: BEGIN_DATE_TIME, dtype: object\n",
      "count     994039\n",
      "unique        16\n",
      "top          CST\n",
      "freq      264714\n",
      "Name: CZ_TIMEZONE, dtype: object\n",
      "count                  994039\n",
      "unique                 478324\n",
      "top       07/31/2012 23:59:00\n",
      "freq                     1107\n",
      "Name: END_DATE_TIME, dtype: object\n",
      "count    994039.000000\n",
      "mean          0.066908\n",
      "std           3.057760\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max        1150.000000\n",
      "Name: INJURIES_DIRECT, dtype: float64\n",
      "count    994039.000000\n",
      "mean          0.008810\n",
      "std           2.454174\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max        2400.000000\n",
      "Name: INJURIES_INDIRECT, dtype: float64\n",
      "count    994039.000000\n",
      "mean          0.010016\n",
      "std           0.287855\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max         158.000000\n",
      "Name: DEATHS_DIRECT, dtype: float64\n",
      "count    994039.000000\n",
      "mean          0.001328\n",
      "std           0.050909\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max          11.000000\n",
      "Name: DEATHS_INDIRECT, dtype: float64\n",
      "count    9.940390e+05\n",
      "mean     4.223994e+05\n",
      "std      1.190188e+08\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.150000e+11\n",
      "Name: DAMAGE_PROPERTY, dtype: float64\n",
      "count    9.940390e+05\n",
      "mean     5.237319e+04\n",
      "std      2.865790e+06\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.050000e+09\n",
      "Name: DAMAGE_CROPS, dtype: float64\n",
      "count              880413\n",
      "unique                 70\n",
      "top       Trained Spotter\n",
      "freq                89530\n",
      "Name: SOURCE, dtype: object\n",
      "count    510630.000000\n",
      "mean         29.616078\n",
      "std          42.338251\n",
      "min           0.000000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max       22000.000000\n",
      "Name: MAGNITUDE, dtype: float64\n",
      "count     245189\n",
      "unique         6\n",
      "top           EG\n",
      "freq      162990\n",
      "Name: MAGNITUDE_TYPE, dtype: object\n",
      "count          41277\n",
      "unique             7\n",
      "top       Heavy Rain\n",
      "freq           36614\n",
      "Name: FLOOD_CAUSE, dtype: object\n",
      "count    174.000000\n",
      "mean       1.086207\n",
      "std        0.428108\n",
      "min        1.000000\n",
      "25%             NaN\n",
      "50%             NaN\n",
      "75%             NaN\n",
      "max        5.000000\n",
      "Name: CATEGORY, dtype: float64\n",
      "count     24924\n",
      "unique       13\n",
      "top          F0\n",
      "freq       9366\n",
      "Name: TOR_F_SCALE, dtype: object\n",
      "count    24896.000000\n",
      "mean         2.860193\n",
      "std          6.441886\n",
      "min          0.000000\n",
      "25%               NaN\n",
      "50%               NaN\n",
      "75%               NaN\n",
      "max        400.000000\n",
      "Name: TOR_LENGTH, dtype: float64\n",
      "count    24896.000000\n",
      "mean       132.837111\n",
      "std        238.183144\n",
      "min          0.000000\n",
      "25%               NaN\n",
      "50%               NaN\n",
      "75%               NaN\n",
      "max       4576.000000\n",
      "Name: TOR_WIDTH, dtype: float64\n",
      "count     1309\n",
      "unique      84\n",
      "top        BMX\n",
      "freq        91\n",
      "Name: TOR_OTHER_WFO, dtype: object\n",
      "count     1309\n",
      "unique      37\n",
      "top         AL\n",
      "freq       148\n",
      "Name: TOR_OTHER_CZ_STATE, dtype: object\n",
      "count    1309.000000\n",
      "mean      100.435447\n",
      "std        75.835911\n",
      "min         1.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       740.000000\n",
      "Name: TOR_OTHER_CZ_FIPS, dtype: float64\n",
      "count          1309\n",
      "unique          595\n",
      "top       JEFFERSON\n",
      "freq             19\n",
      "Name: TOR_OTHER_CZ_NAME, dtype: object\n",
      "count    408306.000000\n",
      "mean          3.454821\n",
      "std           5.115530\n",
      "min           0.000000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max         520.000000\n",
      "Name: BEGIN_RANGE, dtype: float64\n",
      "count     408306\n",
      "unique        17\n",
      "top            N\n",
      "freq       99962\n",
      "Name: BEGIN_AZIMUTH, dtype: object\n",
      "count         631250\n",
      "unique         41664\n",
      "top       COUNTYWIDE\n",
      "freq           19665\n",
      "Name: BEGIN_LOCATION, dtype: object\n",
      "count    191161.000000\n",
      "mean          4.795000\n",
      "std           5.577513\n",
      "min           0.000000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max         176.000000\n",
      "Name: END_RANGE, dtype: float64\n",
      "count     191161\n",
      "unique        20\n",
      "top            N\n",
      "freq       29316\n",
      "Name: END_AZIMUTH, dtype: object\n",
      "count         414496\n",
      "unique         34119\n",
      "top       COUNTYWIDE\n",
      "freq           19717\n",
      "Name: END_LOCATION, dtype: object\n",
      "count    567873.000000\n",
      "mean         37.989446\n",
      "std           4.846587\n",
      "min         -14.350000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max          97.100000\n",
      "Name: BEGIN_LAT, dtype: float64\n",
      "count    567874.000000\n",
      "mean        -64.087901\n",
      "std          80.801729\n",
      "min        -815.100000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max         171.370000\n",
      "Name: BEGIN_LON, dtype: float64\n",
      "count    351105.000000\n",
      "mean         38.193559\n",
      "std          11.350832\n",
      "min         -14.400000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max         483.100000\n",
      "Name: END_LAT, dtype: float64\n",
      "count    351106.000000\n",
      "mean        -48.084223\n",
      "std          99.060125\n",
      "min        -815.100000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max         815.100000\n",
      "Name: END_LON, dtype: float64\n",
      "count                                                747137\n",
      "unique                                               144582\n",
      "top       A strong upper-level disturbance passed throug...\n",
      "freq                                                    294\n",
      "Name: EPISODE_NARRATIVE, dtype: object\n",
      "count          465552\n",
      "unique         394235\n",
      "top       Trees down.\n",
      "freq             1336\n",
      "Name: EVENT_NARRATIVE, dtype: object\n",
      "count    4.463770e+05\n",
      "mean     4.552487e+07\n",
      "std      3.721479e+07\n",
      "min      2.006010e+07\n",
      "25%               NaN\n",
      "50%               NaN\n",
      "75%               NaN\n",
      "max      1.000000e+08\n",
      "Name: LAST_MOD_DATE, dtype: float64\n",
      "count    446377.000000\n",
      "mean       4124.842346\n",
      "std        4036.234968\n",
      "min           0.000000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max        9999.000000\n",
      "Name: LAST_MOD_TIME, dtype: float64\n",
      "count    4.463770e+05\n",
      "mean     2.010261e+07\n",
      "std      1.896445e+04\n",
      "min      2.006010e+07\n",
      "25%               NaN\n",
      "50%               NaN\n",
      "75%               NaN\n",
      "max      2.014011e+07\n",
      "Name: LAST_CERT_DATE, dtype: float64\n",
      "count    446377.000000\n",
      "mean       1316.212988\n",
      "std         400.252899\n",
      "min           0.000000\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max        2359.000000\n",
      "Name: LAST_CERT_TIME, dtype: float64\n",
      "count                  304342\n",
      "unique                  99479\n",
      "top       07/02/2011 18:27:21\n",
      "freq                      204\n",
      "Name: LAST_MOD, dtype: object\n",
      "count              446377\n",
      "unique               9093\n",
      "top       8/20/2008 14:45\n",
      "freq                  671\n",
      "Name: LAST_CERT, dtype: object\n",
      "count    37840.000000\n",
      "mean         1.053066\n",
      "std          0.224167\n",
      "min          1.000000\n",
      "25%               NaN\n",
      "50%               NaN\n",
      "75%               NaN\n",
      "max          2.000000\n",
      "Name: ADDCORR_FLG, dtype: float64\n",
      "count    3.784000e+04\n",
      "mean     2.010506e+07\n",
      "std      2.054233e+04\n",
      "min      2.009041e+07\n",
      "25%               NaN\n",
      "50%               NaN\n",
      "75%               NaN\n",
      "max      2.014013e+07\n",
      "Name: ADDCORR_DATE, dtype: float64\n",
      "count    994039.000000\n",
      "mean          0.087061\n",
      "std           4.036967\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max        2409.000000\n",
      "Name: casualties, dtype: float64\n",
      "count         994039\n",
      "unique          6418\n",
      "top       2012-07-01\n",
      "freq            2447\n",
      "Name: begin_date_full, dtype: object\n",
      "count    9.940390e+05\n",
      "mean     4.747726e+05\n",
      "std      1.191153e+08\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      5.000000e+02\n",
      "max      1.150325e+11\n",
      "Name: Combined_damage, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for column in df1.columns:\n",
    "    print df1[column].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(994039, 62)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the purposes of this project, I have over 900,000 rows of data and 62 unique columns.  After some EDA on the data performed earlier, i have been able to identify reduce some features that will allow me to run my models more efficiently without hitting my CPU. For instance, there are 48 different Event Types, ranging from Tornados, to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "    Given predictor variables x, and a categorical response variable y, build a model for:\n",
    "        – Predicting the value of y for a new value of x\n",
    "        – Understanding the relationship between x and y\n",
    "    e.g. predict a person’s 5-year-survival (yes/no) based on their age, height, weight, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Methods\n",
    "    • Simple linear regression\n",
    "    • Multiple linear regression\n",
    "    • Nonlinear regression (parametric)\n",
    "    • Nonparametric regression:\n",
    "        – Kernel smoothing, spline methods, wavelets\n",
    "        – Trees (1984)\n",
    "    • Machine learning methods:\n",
    "        – Bagging\n",
    "        – Random forests\n",
    "        – Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METHODOLIGY\n",
    "    1 first split the dataset to test and train \n",
    "    2 find the best model through grid search and cross validation \n",
    "    3 after that, evalutates the best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e081634f1a19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Hey, i want to feed differnt y and X's in so i label the x, xdata, and y ytarget/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# stratify = target, does this go here?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. first split the dataset to test and train \n",
    "# Hey, i want to feed differnt y and X's in so i label the x, xdata, and y ytarget/\n",
    "# stratify = target, does this go here?\n",
    "x_train, x_test, y_train, y_test = train_test_split(xdata, ytarget, stratify = ytarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2g find the best model through grid search  \n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, \n",
    "# scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, \n",
    "# pre_dispatch='2*n_jobs', error_score='raise', return_train_score=True)[source]\n",
    "\n",
    "def grid_search\n",
    "GridSearchCV(estimator=model, params, cv),\n",
    "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2cv find the best model through cross validation \n",
    "\n",
    "def cross_val\n",
    "    cv = StratifiedKFold(ytarget, n_folds=3, shuffle=True, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 after that, evalutates the best model on test data\n",
    "\n",
    "\n",
    "def eval_model(model, xdata, ytarget):\n",
    "    train_split(x, y)\n",
    "    model = grid_search(model, x_train, y_train)\n",
    "    cross_validate(model, x, y)\n",
    "    \n",
    "    Fit model\n",
    "    does the grid  search on train\n",
    "    does the cros validation on train\n",
    "    gets the best model\n",
    "    predicts the test value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LineearRegression()\n",
    "best_model = eval_model(lr, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor()\n",
    "best_model = eval_model(dt, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, data, target, params=None):\n",
    "    x_train, x_test, y_train, y_test=train_test_split(data, target, stratify=target)\n",
    "#     print score(model, x_train, y_train), \"\\n\"\n",
    "    cv=get_cv(y_train)\n",
    "    if params:\n",
    "        grid=grid_search(model, params, cv)\n",
    "    \n",
    "        grid.fit(x_train, y_train)\n",
    "        model = grid.best_estimator_\n",
    "        print \"Best Model after Grid Search:\\n\", model\n",
    "        \n",
    "    else:\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "    s=cross_val_score(model, x_train, y_train, cv=cv, n_jobs=-1)\n",
    "    print \"Mean score of the model is: {}\".format(s.mean())\n",
    "    predictions = model.predict(x_test)\n",
    "    \n",
    "    print \"Confusion Matrix:\\n\",confusion_matrix(y_test, predictions), \"\\n\"\n",
    "    print \"Classification Report:\\n\", classification_report(y_test, predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LinearRegression()\n",
    "# class sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "\n",
    "params = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False],\n",
    "}\n",
    "lnr=evaluate_model(LinearRegression(), xdata, ytarget, params)\n",
    "\n",
    "# Going to want to print out the coef_\n",
    "# How many people died? What was the cost? Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lass sklearn.linear_model.LinearRegression(fit_intercept=True, \n",
    "# normalize=False, copy_X=True, n_jobs=1)\n",
    "\n",
    "# LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "#           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "#           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "#           verbose=0, warm_start=False)\n",
    "\n",
    "params = {\n",
    "    'normalise': [True, False],\n",
    "    'penalty':[l1,l2],\n",
    "}\n",
    "lr=evaluate_model(LogisticRegression(), xdata, ytarget, params)\n",
    "\n",
    "# Going to want to print out the coef_\n",
    "# Did they die? Were there any costs? Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier()\n",
    "params = {\n",
    "    'max_depth': [None,1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 10, 25, 50, 100],\n",
    "}\n",
    "dtc=evaluate_model(DecisionTreeClassifier(), xdata, ytarget, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DecisionTreeRegressor() could be pretty much the same params\n",
    "# (criterion='mse', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, max_features=None, \n",
    "# random_state=None, max_leaf_nodes=None, min_impurity_split=1e-07, presort=False)[source]\n",
    "\n",
    "\n",
    "params = {\n",
    "    'max_depth': [None,1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 10, 25, 50, 100],\n",
    "}\n",
    "dtr=evaluate_model(DecisionTreeRegressor(),xdata, ytarget, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200],\n",
    "    'max_depth': [None,1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 10, 25, 50, 100],\n",
    "}\n",
    "rfc=evaluate_model(RandomForestClassifier(class_weight='balanced', n_jobs=-1), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestRegressor\n",
    "# (n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2, \n",
    "# min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "# max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, \n",
    "# n_jobs=1, random_state=None, verbose=0, warm_start=False)[source]\n",
    "\n",
    "# RandomForestRegressor()\n",
    "params = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200],\n",
    "    'max_depth': [None,1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 10, 25, 50, 100],\n",
    "}\n",
    "rfr=evaluate_model(RandomForestRegressor(class_weight='balanced', n_jobs=-1), x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ExtraTreesClassifier\n",
    "params = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200],\n",
    "    'max_depth': [None,1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 10, 25, 50, 100],\n",
    "}\n",
    "etc=evaluate_model(ExtraTreesClassifier(class_weight='balanced', n_jobs=-1), x, y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ExtraTreesRegressor\n",
    "# class sklearn.ensemble.ExtraTreesRegressor(n_estimators=10, \n",
    "# criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, \n",
    "# bootstrap=False, oob_score=False, n_jobs=1, \n",
    "# random_state=None, verbose=0, warm_start=False)[source]¶\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200],\n",
    "    'max_depth': [None,1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 10, 25, 50, 100],\n",
    "}\n",
    "etr=evaluate_model(ExtraTreesRegressor(class_weight='balanced', n_jobs=-1), x, y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97741935483870968"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Train Test Split ( I will do K fold cross val below)\n",
    "logit.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97855483870967741"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "GridSearchCV(cv=None,\n",
    "       estimator=LogisticRegression(C=1.0, intercept_scaling=1, dual=False, fit_intercept=True,\n",
    "          penalty='l2', tol=0.0001),\n",
    "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97770322580645164"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-c1e1bf2bd693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ugp/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coef_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             raise NotFittedError(\"This %(name)s instance is not fitted \"\n\u001b[0;32m--> 242\u001b[0;31m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet"
     ]
    }
   ],
   "source": [
    "predictions = logit.predict(x_test)\n",
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "% matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             casualties   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     10.01\n",
      "Date:                Mon, 05 Dec 2016   Prob (F-statistic):           5.83e-58\n",
      "Time:                        09:37:18   Log-Likelihood:            -4.5229e+05\n",
      "No. Observations:              155000   AIC:                         9.047e+05\n",
      "Df Residuals:                  154961   BIC:                         9.050e+05\n",
      "Df Model:                          38                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Astronomical Low Tide          0      2.003          0      1.000        -3.925     3.925\n",
      "Avalanche                 1.4318      0.675      2.121      0.034         0.109     2.755\n",
      "Blizzard                  0.1423      0.083      1.710      0.087        -0.021     0.305\n",
      "Coastal Flood             0.0308      0.210      0.147      0.883        -0.381     0.443\n",
      "Cold/Wind Chill           0.0412      0.063      0.656      0.512        -0.082     0.165\n",
      "Debris Flow               0.1957      0.660      0.296      0.767        -1.098     1.490\n",
      "Dense Fog                 0.2973      0.126      2.364      0.018         0.051     0.544\n",
      "Drought                        0      0.079          0      1.000        -0.154     0.154\n",
      "Dust Devil                0.1600      0.896      0.179      0.858        -1.595     1.915\n",
      "Dust Storm                4.2593      0.862      4.942      0.000         2.570     5.948\n",
      "Flash Flood               0.5176      0.044     11.801      0.000         0.432     0.604\n",
      "Flood                     0.3008      0.054      5.566      0.000         0.195     0.407\n",
      "Freezing Fog              0.0500      1.001      0.050      0.960        -1.913     2.013\n",
      "Frost/Freeze              0.0157      0.281      0.056      0.955        -0.535     0.566\n",
      "Funnel Cloud              0.0009      0.133      0.007      0.995        -0.259     0.261\n",
      "Hail                      0.0040      0.025      0.165      0.869        -0.044     0.052\n",
      "Heat                      0.5962      0.087      6.861      0.000         0.426     0.767\n",
      "Heavy Rain                0.0456      0.091      0.500      0.617        -0.133     0.224\n",
      "Heavy Snow                0.0404      0.042      0.959      0.338        -0.042     0.123\n",
      "High Surf                 0.0643      0.164      0.392      0.695        -0.257     0.386\n",
      "High Wind                 0.0413      0.046      0.905      0.366        -0.048     0.131\n",
      "Hurricane (Typhoon)       0.1343      0.223      0.601      0.548        -0.303     0.572\n",
      "Ice Storm                 0.0845      0.082      1.037      0.300        -0.075     0.244\n",
      "Lake-Effect Snow               0      0.387          0      1.000        -0.758     0.758\n",
      "Lightning                 0.3865      0.086      4.501      0.000         0.218     0.555\n",
      "Marine High Wind          1.5000      3.166      0.474      0.636        -4.706     7.706\n",
      "Rip Current               1.6979      0.457      3.715      0.000         0.802     2.594\n",
      "Seiche                         0      1.493          0      1.000        -2.926     2.926\n",
      "Sleet                          0      0.416          0      1.000        -0.815     0.815\n",
      "Storm Surge/Tide          0.2544      0.419      0.607      0.544        -0.568     1.076\n",
      "Strong Wind               0.0366      0.097      0.377      0.706        -0.154     0.227\n",
      "Thunderstorm Wind         0.0498      0.024      2.076      0.038         0.003     0.097\n",
      "Tornado                   0.9774      0.068     14.369      0.000         0.844     1.111\n",
      "Tropical Storm            0.2831      0.272      1.043      0.297        -0.249     0.815\n",
      "Volcanic Ash                   0      3.166          0      1.000        -6.206     6.206\n",
      "Waterspout                0.0018      0.189      0.009      0.992        -0.369     0.373\n",
      "Wildfire                  0.5830      0.285      2.046      0.041         0.025     1.141\n",
      "Winter Storm              0.0845      0.043      1.953      0.051        -0.000     0.169\n",
      "Winter Weather            0.1351      0.077      1.759      0.079        -0.015     0.286\n",
      "==============================================================================\n",
      "Omnibus:                   629410.066   Durbin-Watson:                   1.269\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):    1329719431119.255\n",
      "Skew:                         107.553   Prob(JB):                         0.00\n",
      "Kurtosis:                   14350.326   Cond. No.                         132.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(y,X)    # Describe model\n",
    "res = mod.fit()       # Fit model\n",
    "print res.summary()   # Summarize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             casualties   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     10.01\n",
      "Date:                Mon, 05 Dec 2016   Prob (F-statistic):           5.83e-58\n",
      "Time:                        09:37:18   Log-Likelihood:            -4.5229e+05\n",
      "No. Observations:              155000   AIC:                         9.047e+05\n",
      "Df Residuals:                  154961   BIC:                         9.050e+05\n",
      "Df Model:                          38                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Astronomical Low Tide          0      2.003          0      1.000        -3.925     3.925\n",
      "Avalanche                 1.4318      0.675      2.121      0.034         0.109     2.755\n",
      "Blizzard                  0.1423      0.083      1.710      0.087        -0.021     0.305\n",
      "Coastal Flood             0.0308      0.210      0.147      0.883        -0.381     0.443\n",
      "Cold/Wind Chill           0.0412      0.063      0.656      0.512        -0.082     0.165\n",
      "Debris Flow               0.1957      0.660      0.296      0.767        -1.098     1.490\n",
      "Dense Fog                 0.2973      0.126      2.364      0.018         0.051     0.544\n",
      "Drought                        0      0.079          0      1.000        -0.154     0.154\n",
      "Dust Devil                0.1600      0.896      0.179      0.858        -1.595     1.915\n",
      "Dust Storm                4.2593      0.862      4.942      0.000         2.570     5.948\n",
      "Flash Flood               0.5176      0.044     11.801      0.000         0.432     0.604\n",
      "Flood                     0.3008      0.054      5.566      0.000         0.195     0.407\n",
      "Freezing Fog              0.0500      1.001      0.050      0.960        -1.913     2.013\n",
      "Frost/Freeze              0.0157      0.281      0.056      0.955        -0.535     0.566\n",
      "Funnel Cloud              0.0009      0.133      0.007      0.995        -0.259     0.261\n",
      "Hail                      0.0040      0.025      0.165      0.869        -0.044     0.052\n",
      "Heat                      0.5962      0.087      6.861      0.000         0.426     0.767\n",
      "Heavy Rain                0.0456      0.091      0.500      0.617        -0.133     0.224\n",
      "Heavy Snow                0.0404      0.042      0.959      0.338        -0.042     0.123\n",
      "High Surf                 0.0643      0.164      0.392      0.695        -0.257     0.386\n",
      "High Wind                 0.0413      0.046      0.905      0.366        -0.048     0.131\n",
      "Hurricane (Typhoon)       0.1343      0.223      0.601      0.548        -0.303     0.572\n",
      "Ice Storm                 0.0845      0.082      1.037      0.300        -0.075     0.244\n",
      "Lake-Effect Snow               0      0.387          0      1.000        -0.758     0.758\n",
      "Lightning                 0.3865      0.086      4.501      0.000         0.218     0.555\n",
      "Marine High Wind          1.5000      3.166      0.474      0.636        -4.706     7.706\n",
      "Rip Current               1.6979      0.457      3.715      0.000         0.802     2.594\n",
      "Seiche                         0      1.493          0      1.000        -2.926     2.926\n",
      "Sleet                          0      0.416          0      1.000        -0.815     0.815\n",
      "Storm Surge/Tide          0.2544      0.419      0.607      0.544        -0.568     1.076\n",
      "Strong Wind               0.0366      0.097      0.377      0.706        -0.154     0.227\n",
      "Thunderstorm Wind         0.0498      0.024      2.076      0.038         0.003     0.097\n",
      "Tornado                   0.9774      0.068     14.369      0.000         0.844     1.111\n",
      "Tropical Storm            0.2831      0.272      1.043      0.297        -0.249     0.815\n",
      "Volcanic Ash                   0      3.166          0      1.000        -6.206     6.206\n",
      "Waterspout                0.0018      0.189      0.009      0.992        -0.369     0.373\n",
      "Wildfire                  0.5830      0.285      2.046      0.041         0.025     1.141\n",
      "Winter Storm              0.0845      0.043      1.953      0.051        -0.000     0.169\n",
      "Winter Weather            0.1351      0.077      1.759      0.079        -0.015     0.286\n",
      "==============================================================================\n",
      "Omnibus:                   629410.066   Durbin-Watson:                   1.269\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):    1329719431119.255\n",
      "Skew:                         107.553   Prob(JB):                         0.00\n",
      "Kurtosis:                   14350.326   Cond. No.                         132.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(y,X)    # Describe model\n",
    "print res.summary()   # Summarize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Astronomical Low Tide    0.000000\n",
       "Lake-Effect Snow         0.000000\n",
       "Seiche                   0.000000\n",
       "Drought                  0.000000\n",
       "Sleet                    0.000000\n",
       "Volcanic Ash             0.000000\n",
       "Funnel Cloud             0.000876\n",
       "Waterspout               0.001786\n",
       "Hail                     0.004050\n",
       "Frost/Freeze             0.015748\n",
       "Coastal Flood            0.030837\n",
       "Strong Wind              0.036603\n",
       "Heavy Snow               0.040364\n",
       "Cold/Wind Chill          0.041239\n",
       "High Wind                0.041252\n",
       "Heavy Rain               0.045624\n",
       "Thunderstorm Wind        0.049795\n",
       "Freezing Fog             0.050000\n",
       "High Surf                0.064343\n",
       "Ice Storm                0.084521\n",
       "Winter Storm             0.084524\n",
       "Hurricane (Typhoon)      0.134328\n",
       "Winter Weather           0.135119\n",
       "Blizzard                 0.142265\n",
       "Dust Devil               0.160000\n",
       "Debris Flow              0.195652\n",
       "Storm Surge/Tide         0.254386\n",
       "Tropical Storm           0.283088\n",
       "Dense Fog                0.297319\n",
       "Flood                    0.300845\n",
       "Lightning                0.386539\n",
       "Flash Flood              0.517605\n",
       "Wildfire                 0.582996\n",
       "Heat                     0.596234\n",
       "Tornado                  0.977388\n",
       "Avalanche                1.431818\n",
       "Marine High Wind         1.500000\n",
       "Rip Current              1.697917\n",
       "Dust Storm               4.259259\n",
       "dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.params.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cv(target):\n",
    "    return StratifiedKFold(target, n_folds=3, shuffle=True, random_state=41)\n",
    "def score(model, data, target):\n",
    "    model.fit(data, target)\n",
    "    return model.score(data, target)\n",
    "def grid_search(model, params, cv):\n",
    "    return GridSearchCV(estimator=model, \n",
    "                    param_grid=params,\n",
    "                    cv=cv\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
